# distributed-data-preprocessing-with-dask
A distributed data engineering pipeline using Dask (or PySpark) to clean and feature engineer massive datasets in parallel.
